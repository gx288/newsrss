import feedparser
import os
import json
import tempfile
import shutil
from google import genai
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from bs4 import BeautifulSoup
import gspread.exceptions
from icrawler.builtin import BingImageCrawler

# Cáº¥u hÃ¬nh
SHEET_ID = "14tqKftTqlesnb0NqJZU-_f1EsWWywYqO36NiuDdmaTo"
RSS_SHEET_NAME = "RSS"
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GOOGLE_SHEETS_CREDENTIALS = os.getenv("GOOGLE_SHEETS_CREDENTIALS")

# Danh sÃ¡ch model Æ°u tiÃªn (cáº­p nháº­t cho Gemini hiá»‡n táº¡i thÃ¡ng 12/2025)
MODEL_PRIORITY = [
    "gemini-1.5-pro",
    "gemini-1.5-flash",
    "gemini-1.0-pro",
]

# Prompt
PROMPT = """
TÃ³m táº¯t thÃ nh vÃ i Ä‘oáº¡n vÄƒn ngáº¯n (khÃ´ng dÃ¹ng cÃ¡c Ä‘oáº¡n tÃ³m táº¯t ngáº¯n á»Ÿ Ä‘áº§u Ä‘oáº¡n vÄƒn), cÃ³ emoji (khÃ¡c nhau) phÃ¹ há»£p vá»›i ná»™i dung cá»§a Ä‘oáº¡n Ä‘áº·t á»Ÿ Ä‘áº§u dÃ²ng vÃ  hashtag á»Ÿ cuá»‘i cÃ¹ng cá»§a bÃ i viáº¿t. Khoáº£ng 500-1000 kÃ­ tá»± phÃ¹ há»£p vá»›i Facebook. HÃ£y viáº¿t thÃ nh Ä‘oáº¡n vÄƒn trÃ´i cháº£y, khÃ´ng dÃ¹ng "tiÃªu Ä‘á» ngáº¯n". HÃ£y Ä‘áº·t táº¥t cáº£ hashtag á»Ÿ cuá»‘i bÃ i viáº¿t, khÃ´ng Ä‘áº·t á»Ÿ cuá»‘i má»—i Ä‘oáº¡n. ThÃªm hashtag #dongysonha. Viáº¿t theo quy táº¯c 4C, Ä‘áº§y Ä‘á»§ Ã½, ná»™i dung phÃ¹ há»£p vá»›i tiÃªu Ä‘á», giáº£i quyáº¿t Ä‘Æ°á»£c tÃ¬nh tráº¡ng, cÃ¢u há»i trong tiÃªu Ä‘á», lÃ m thá»a mÃ£n ngÆ°á»i Ä‘á»c, trung thá»±c, khÃ´ng dÃ¹ng Ä‘áº¡i tá»« nhÃ¢n xÆ°ng. Káº¿t quáº£ tráº£ vá» cÃ³ 1 pháº§n tiÃªu Ä‘á» Ä‘Æ°á»£c VIáº¾T IN HOA Táº¤T Cáº¢ vÃ  "ğŸ‘‡ğŸ‘‡ğŸ‘‡" cuá»‘i tiÃªu Ä‘á».
"""

# Táº¡o client Gemini
client = genai.Client(api_key=GEMINI_API_KEY)

# Biáº¿n theo dÃµi
processed_count = 0
skipped_count = 0
error_count = 0

def get_gspread_client():
    print("Báº¯t Ä‘áº§u cáº¥u hÃ¬nh Google Sheets client...")
    creds_dict = json.loads(GOOGLE_SHEETS_CREDENTIALS)
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, ["https://www.googleapis.com/auth/spreadsheets"])
    client = gspread.authorize(creds)
    print("HoÃ n táº¥t cáº¥u hÃ¬nh Google Sheets client.")
    return client

def get_rss_feeds():
    print("Báº¯t Ä‘áº§u láº¥y danh sÃ¡ch RSS feed tá»« Google Sheet...")
    try:
        client = get_gspread_client()
        sheet = client.open_by_key(SHEET_ID).worksheet(RSS_SHEET_NAME)
        data = sheet.get_all_values()
        if len(data) < 2:
            print("KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u RSS feed.")
            return []
        feeds = []
        for row in data[1:]:
            rss_url = row[0].strip()
            sheet_name = row[1].strip() if len(row) > 1 else ""
            if rss_url and sheet_name:
                feeds.append({"rss_url": rss_url, "sheet_name": sheet_name})
                print(f"ÄÃ£ thÃªm RSS: {rss_url} -> {sheet_name}")
        print(f"Tá»•ng cá»™ng {len(feeds)} RSS feed.")
        return feeds
    except Exception as e:
        print(f"Lá»—i khi láº¥y danh sÃ¡ch RSS feed: {str(e)}")
        return []

def get_existing_links(sheet_name):
    print(f"Báº¯t Ä‘áº§u láº¥y danh sÃ¡ch link Ä‘Ã£ xá»­ lÃ½ tá»« trang tÃ­nh {sheet_name}...")
    try:
        client = get_gspread_client()
        sheet = client.open_by_key(SHEET_ID).worksheet(sheet_name)
        links = sheet.col_values(3)[1:]  # Cá»™t 3: Link
        print(f"ÄÃ£ láº¥y {len(links)} link cÅ©.")
        return set(links)
    except gspread.exceptions.WorksheetNotFound:
        print(f"Trang tÃ­nh {sheet_name} chÆ°a tá»“n táº¡i â†’ coi nhÆ° chÆ°a cÃ³ link nÃ o.")
        return set()
    except Exception as e:
        print(f"Lá»—i khi láº¥y link: {str(e)}")
        return set()

def search_image_with_icrawler(query):
    """
    DÃ¹ng icrawler Ä‘á»ƒ tÃ¬m vÃ  táº£i 1 áº£nh Ä‘áº§u tiÃªn tá»« Bing (kÃ­ch thÆ°á»›c medium trá»Ÿ lÃªn).
    Tráº£ vá» URL cá»§a áº£nh Ä‘áº§u tiÃªn tÃ¬m Ä‘Æ°á»£c.
    """
    temp_dir = tempfile.mkdtemp()
    try:
        crawler = BingImageCrawler(
            downloader_threads=2,
            storage={'root_dir': temp_dir},
            log_level='INFO'  # CÃ³ thá»ƒ Ä‘á»•i thÃ nh 'DEBUG' náº¿u muá»‘n xem chi tiáº¿t
        )
        # Filters: size >= medium, chá»‰ láº¥y 5 Ä‘á»ƒ nhanh, min_size Ä‘á»ƒ Ä‘áº£m báº£o cháº¥t lÆ°á»£ng
        filters = dict(size='medium')  # 'large', 'medium', 'small'
        crawler.crawl(
            keyword=query,
            filters=filters,
            max_num=5,  # Chá»‰ cáº§n vÃ i cÃ¡i Ä‘á»ƒ chá»n
            min_size=(400, 400)  # KÃ­ch thÆ°á»›c tá»‘i thiá»ƒu
        )
        
        # TÃ¬m file áº£nh Ä‘áº§u tiÃªn trong thÆ° má»¥c temp (icrawler lÆ°u theo sá»‘)
        downloaded_files = []
        for root, _, files in os.walk(temp_dir):
            for f in files:
                if f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp')):
                    downloaded_files.append(os.path.join(root, f))
        
        if downloaded_files:
            # Láº¥y áº£nh Ä‘áº§u tiÃªn
            first_image_path = downloaded_files[0]
            print(f"ÄÃ£ tÃ¬m Ä‘Æ°á»£c áº£nh fallback tá»« Bing (icrawler): {first_image_path}")
            return first_image_path  # Tráº£ vá» path local Ä‘á»ƒ upload sau
        else:
            print("icrawler khÃ´ng táº£i Ä‘Æ°á»£c áº£nh nÃ o.")
            return None
    except Exception as e:
        print(f"Lá»—i khi dÃ¹ng icrawler tÃ¬m áº£nh: {str(e)}")
        return None
    finally:
        # Dá»n dáº¹p temp dir (giá»¯ láº¡i náº¿u muá»‘n debug)
        shutil.rmtree(temp_dir, ignore_errors=True)

def get_rss_feed(rss_url, sheet_name):
    print(f"Báº¯t Ä‘áº§u láº¥y dá»¯ liá»‡u tá»« RSS feed: {rss_url}...")
    feed = feedparser.parse(rss_url)
    if not feed.entries:
        print(f"KhÃ´ng cÃ³ entry nÃ o trong RSS {rss_url}.")
        return []
    existing_links = get_existing_links(sheet_name)
    articles = []
    for entry in feed.entries:
        link = entry.link
        if link in existing_links:
            global skipped_count
            skipped_count += 1
            continue
        title = entry.title
        description = entry.description
        pubdate = entry.get('published') or entry.get('pubDate') or entry.get('updated') or ''
        
        image_url = None
        local_image_path = None  # Äá»ƒ lÆ°u path náº¿u dÃ¹ng icrawler
        
        # Æ¯u tiÃªn áº£nh tá»« enclosures
        if hasattr(entry, 'enclosures') and entry.enclosures:
            for enc in entry.enclosures:
                if enc.get('type', '').startswith('image/'):
                    image_url = enc.get('url')
                    break
        
        # Náº¿u khÃ´ng, láº¥y tá»« description
        if not image_url:
            soup = BeautifulSoup(description, 'html.parser')
            img_tag = soup.find('img')
            if img_tag and img_tag.get('src'):
                src = img_tag['src']
                if src.startswith('http') and "holder.png" not in src:
                    image_url = src
        
        # Náº¿u váº«n khÃ´ng cÃ³ hoáº·c placeholder â†’ dÃ¹ng icrawler tÃ¬m fallback
        if not image_url or "holder.png" in str(image_url):
            print(f"KhÃ´ng cÃ³ áº£nh há»£p lá»‡ tá»« RSS cho bÃ i: {title}. Äang tÃ¬m fallback báº±ng icrawler...")
            local_image_path = search_image_with_icrawler(title)
            # Náº¿u tÃ¬m Ä‘Æ°á»£c local path, sáº½ upload lÃªn Ä‘Ã¢u Ä‘Ã³ hoáº·c Ä‘á»ƒ URL = path (nhÆ°ng Sheets cháº¥p nháº­n URL http)
            # Váº¥n Ä‘á»: icrawler táº£i vá» local, nhÆ°ng Sheets cáº§n URL cÃ´ng khai.
            # Giáº£i phÃ¡p táº¡m: Náº¿u báº¡n cÃ³ hosting (Imgur, Cloudinary...), upload lÃªn láº¥y URL.
            # á» Ä‘Ã¢y táº¡m Ä‘á»ƒ None náº¿u khÃ´ng cÃ³ URL cÃ´ng khai.
            # Hoáº·c dÃ¹ng placeholder default.
            if local_image_path:
                print("TÃ¬m Ä‘Æ°á»£c áº£nh local nhÆ°ng chÆ°a cÃ³ cÃ¡ch upload â†’ táº¡m bá» qua áº£nh fallback.")
                # TODO: ThÃªm upload to Imgur hoáº·c Google Drive Ä‘á»ƒ láº¥y link cÃ´ng khai náº¿u cáº§n.
        
        articles.append({
            "title": title,
            "description": description,
            "link": link,
            "image_url": image_url,  # URL tá»« RSS hoáº·c None
            "local_image_path": local_image_path,  # Náº¿u cÃ³ fallback local
            "pubdate": pubdate
        })
        print(f"ÄÃ£ thÃªm bÃ i má»›i: {title} (áº£nh: {'cÃ³ URL' if image_url else 'khÃ´ng hoáº·c local'})")
        
        if len(articles) >= 5:
            print(f"Äáº¡t giá»›i háº¡n 5 bÃ i má»›i cho RSS {rss_url}.")
            break
    print(f"HoÃ n táº¥t: {len(articles)} bÃ i má»›i sáº½ xá»­ lÃ½.")
    return articles

# CÃ¡c hÃ m cÃ²n láº¡i giá»¯ nguyÃªn (rewrite_content, append_to_gsheet, main)
# ... (copy tá»« code trÆ°á»›c)

def rewrite_content(title, description):
    print(f"Báº¯t Ä‘áº§u tÃ³m táº¯t bÃ i: {title}")
    prompt = f"{PROMPT}\nTiÃªu Ä‘á»: {title}\nMÃ´ táº£: {description}"
    for model_name in MODEL_PRIORITY:
        print(f"Thá»­ model: {model_name}")
        try:
            response = client.models.generate_content(
                model=model_name,
                contents=prompt
            )
            content = response.text.strip()
            parts = content.split("ğŸ‘‡ğŸ‘‡ğŸ‘‡")
            if len(parts) < 2:
                print(f"Äá»‹nh dáº¡ng khÃ´ng há»£p lá»‡ tá»« {model_name}. Thá»­ model khÃ¡c...")
                continue
            summary_title = parts[0].strip()
            summary_content = parts[1].strip()
            print(f"TÃ³m táº¯t thÃ nh cÃ´ng vá»›i {model_name}")
            return summary_title, summary_content
        except Exception as e:
            print(f"Lá»—i vá»›i {model_name}: {str(e)}")
            continue
    print(f"Háº¿t model kháº£ dá»¥ng cho bÃ i '{title}'.")
    return None, None

def append_to_gsheet(title, summary_title, summary_content, link, image_url, pubdate, sheet_name):
    print(f"Báº¯t Ä‘áº§u ghi bÃ i '{title}' vÃ o {sheet_name}...")
    try:
        client_gs = get_gspread_client()
        spreadsheet = client_gs.open_by_key(SHEET_ID)
        try:
            sheet = spreadsheet.worksheet(sheet_name)
        except gspread.exceptions.WorksheetNotFound:
            print(f"Táº¡o sheet má»›i: {sheet_name}")
            sheet = spreadsheet.add_worksheet(title=sheet_name, rows=100, cols=10)
        header = ["Original Title", "Summary", "Link", "Image URL", "Publish Date", "áº¢nh", "NgÃ y"]
        if not sheet.get_all_values():
            sheet.insert_row(header, 1)
        row = [title, summary_title + "\nğŸ‘‡ğŸ‘‡ğŸ‘‡\n" + summary_content, link, image_url or "", pubdate, "", ""]
        sheet.insert_row(row, 2)
        image_formula = '=IF(D2<>""; IMAGE(D2); "")'
        date_formula = '=IF(E2<>""; DATE(MID(E2; FIND(","; E2)+9; 4); MATCH(MID(E2; FIND(","; E2)+5; 3); {"Jan";"Feb";"Mar";"Apr";"May";"Jun";"Jul";"Aug";"Sep";"Oct";"Nov";"Dec"}; 0); MID(E2; FIND(","; E2)+2; 2)); "")'
        sheet.update('F2', [[image_formula]], value_input_option='USER_ENTERED')
        sheet.update('G2', [[date_formula]], value_input_option='USER_ENTERED')
        global processed_count
        processed_count += 1
    except Exception as e:
        print(f"Lá»—i ghi sheet: {str(e)}")
        global error_count
        error_count += 1

def main():
    print("=== Báº®T Äáº¦U CHáº Y SCRIPT ===")
    feeds = get_rss_feeds()
    if not feeds:
        print("KhÃ´ng cÃ³ RSS nÃ o Ä‘á»ƒ xá»­ lÃ½.")
        return
    for feed in feeds:
        rss_url = feed["rss_url"]
        sheet_name = feed["sheet_name"]
        print(f"\n=== Xá»¬ LÃ RSS: {rss_url} ===")
        articles = get_rss_feed(rss_url, sheet_name)
        if not articles:
            print("KhÃ´ng cÃ³ bÃ i má»›i.")
            continue
        for i, article in enumerate(articles, 1):
            print(f"\nXá»­ lÃ½ bÃ i {i}/{len(articles)}: {article['title']}")
            summary_title, summary_content = rewrite_content(article["title"], article["description"])
            if not summary_title or not summary_content:
                print(f"Bá» qua bÃ i do lá»—i tÃ³m táº¯t.")
                global error_count
                error_count += 1
                continue
            append_to_gsheet(
                article["title"], summary_title, summary_content,
                article["link"], article["image_url"], article["pubdate"], sheet_name
            )
    print("\n=== Tá»”NG Káº¾T ===")
    print(f"ThÃ nh cÃ´ng: {processed_count}")
    print(f"TrÃ¹ng láº·p: {skipped_count}")
    print(f"Lá»—i: {error_count}")
    print("=== Káº¾T THÃšC ===")

if __name__ == "__main__":
    main()
